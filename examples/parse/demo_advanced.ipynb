{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced RAG with LlamaParse\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/run-llama/llama_parse/blob/main/examples/demo_advanced.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "This notebook is a complete walkthrough for using LlamaParse with advanced indexing/retrieval techniques in LlamaIndex over the Apple 10K Filing. \n",
    "\n",
    "This allows us to ask sophisticated questions that aren't possible with \"naive\" parsing/indexing techniques with existing models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index llama-cloud-services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget \"https://s2.q4cdn.com/470004039/files/doc_financials/2021/q4/_10-K-2021-(As-Filed).pdf\" -O apple_2021_10k.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some OpenAI and LlamaParse details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# API access to llama-cloud\n",
    "os.environ[\"LLAMA_CLOUD_API_KEY\"] = \"llx-...\"\n",
    "\n",
    "# Using OpenAI API for embeddings/llms\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import Settings\n",
    "\n",
    "embed_model = OpenAIEmbedding(model_name=\"text-embedding-3-small\")\n",
    "llm = OpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using brand new `LlamaParse` PDF reader for PDF Parsing\n",
    "\n",
    "We also compare three different retrieval/query engine strategies:\n",
    "1. Baseline using default parsing from `SimpleDirectoryReader`\n",
    "2. Using raw markdown text as nodes for building index and apply simple query engine for generating the results;\n",
    "3. Using markdown + page screenshots to help retrieve the proper nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id e403a457-1721-4093-82bf-4a316d2d637a\n"
     ]
    }
   ],
   "source": [
    "from llama_cloud_services import LlamaParse\n",
    "\n",
    "result = await LlamaParse(take_screenshot=True).aparse(\"./apple_2021_10k.pdf\")\n",
    "\n",
    "markdown_nodes = await result.aget_markdown_nodes(split_by_page=True)\n",
    "screenshot_image_nodes = await result.aget_image_nodes(\n",
    "    include_screenshot_images=True,\n",
    "    include_object_images=False,\n",
    "    image_download_dir=\"./images\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "baseline_documents = SimpleDirectoryReader(\n",
    "    input_files=[\"apple_2021_10k.pdf\"]\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Baseline Index\n",
    "\n",
    "For comparison, we setup a naive RAG pipeline with default parsing and standard chunking, indexing, retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "baseline_index = VectorStoreIndex.from_documents(baseline_documents)\n",
    "baseline_query_engine = baseline_index.as_query_engine(similarity_top_k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup our LlamaParse Indexes\n",
    "\n",
    "Using both the markdown and screenshot images, we can build two different indexes.\n",
    "\n",
    "1. An index over just the markdown documents\n",
    "2. A custom index that uses the markdown + screenshot images to help with response quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "markdown_index = VectorStoreIndex(nodes=markdown_nodes)\n",
    "markdown_query_engine = markdown_index.as_query_engine(similarity_top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.indices import MultiModalVectorStoreIndex\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import Settings\n",
    "\n",
    "# could also use other API-based multimodal models like voyageai or jinaai\n",
    "# Note: this may take quite a while if running on CPU!\n",
    "image_embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"llamaindex/vdr-2b-multi-v1\",\n",
    "    embed_batch_size=2,\n",
    "    trust_remote_code=True,\n",
    "    cache_folder=\"./hf_cache_2\",\n",
    "    device=\"cpu\",  # set to \"cuda\" if you have a GPU or remove to auto-detect\n",
    ")\n",
    "\n",
    "multi_modal_index = MultiModalVectorStoreIndex(\n",
    "    nodes=[*markdown_nodes, *screenshot_image_nodes],\n",
    "    embed_model=Settings.embed_model,\n",
    "    image_embed_model=image_embed_model,\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we will create a custom query engine that does a few things\n",
    "1. Retrieves both image nodes and text nodes\n",
    "2. Combines them into two lists -- one where images and texts come from the same page, and one where we have texts alone\n",
    "3. Use a Jinja-based `RichPromptTemplate` to format the retrieved content automatically into a list of multimodal chat messages\n",
    "4. Send our messages to the LLM and return a result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.async_utils import asyncio_run\n",
    "from llama_index.core.llms import LLM\n",
    "from llama_index.core.query_engine import CustomQueryEngine\n",
    "from llama_index.core.prompts import RichPromptTemplate\n",
    "from llama_index.core.response import Response\n",
    "from llama_index.core.schema import NodeWithScore\n",
    "from llama_index.core import Settings\n",
    "\n",
    "TEXT_IMAGE_PROMPT_TEMPLATE = RichPromptTemplate(\n",
    "    \"\"\"\n",
    "<context>\n",
    "Here is some retrieved content from a knowledge base:\n",
    "{% for image_path, text in images_and_texts %}\n",
    "<page>\n",
    "<text>{{ text }}</text>\n",
    "<image>{{ image_path | image }}</image>\n",
    "</page>\n",
    "{% endfor %}\n",
    "{% for text in texts %}\n",
    "<page>\n",
    "<text>{{ text }}</text>\n",
    "</page>\n",
    "{% endfor %}\n",
    "</context>\n",
    "\n",
    "Using the context, answer the following question:\n",
    "<query>{{ query_str }}</query>\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "class SimpleMultiModalQueryEngine(CustomQueryEngine):\n",
    "    def __init__(\n",
    "        self,\n",
    "        index: MultiModalVectorStoreIndex,\n",
    "        image_top_k: int = 4,\n",
    "        text_top_k: int = 4,\n",
    "        llm: LLM | None = None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self._retriever = index.as_retriever(\n",
    "            similarity_top_k=text_top_k, image_similarity_top_k=image_top_k\n",
    "        )\n",
    "        self._llm = llm or Settings.llm\n",
    "\n",
    "    def _match_images_and_texts(\n",
    "        self, text_results: list[NodeWithScore], image_results: list[NodeWithScore]\n",
    "    ) -> tuple[list[NodeWithScore], list[NodeWithScore]]:\n",
    "        # combine results, prioritize images and texts\n",
    "        # if both an image and matching text was retrieved, that is a strong indicator\n",
    "        images_and_texts = []\n",
    "        text_keys = {\n",
    "            (x.metadata[\"page_number\"], x.metadata[\"file_name\"]): x\n",
    "            for x in text_results\n",
    "        }\n",
    "        for image_result in image_results:\n",
    "            key = (\n",
    "                image_result.metadata[\"page_number\"],\n",
    "                image_result.metadata[\"file_name\"],\n",
    "            )\n",
    "            # add matching text to results if available\n",
    "            if key in text_keys:\n",
    "                text_result = text_keys[key]\n",
    "                images_and_texts.append(\n",
    "                    (image_result.node.image_path, text_result.node.text)\n",
    "                )\n",
    "\n",
    "                # remove from list\n",
    "                text_keys.pop(key)\n",
    "\n",
    "        # get the remaining texts as a fallback\n",
    "        texts = [result.node.text for result in text_keys.values()]\n",
    "\n",
    "        return images_and_texts, texts\n",
    "\n",
    "    def custom_query(self, query_str: str) -> Response:\n",
    "        # wrap the async method to avoid code duplication\n",
    "        # asyncio_run is a slightly safer asyncio.run() call\n",
    "        return asyncio_run(self.acustom_query(query_str))\n",
    "\n",
    "    async def acustom_query(self, query_str: str) -> Response:\n",
    "        text_results = await self._retriever.atext_retrieve(query_str)\n",
    "        image_results = await self._retriever.atext_to_image_retrieve(query_str)\n",
    "\n",
    "        images_and_texts, texts = self._match_images_and_texts(\n",
    "            text_results, image_results\n",
    "        )\n",
    "        messages = TEXT_IMAGE_PROMPT_TEMPLATE.format_messages(\n",
    "            images_and_texts=images_and_texts, texts=texts, query_str=str(query_str)\n",
    "        )\n",
    "\n",
    "        response = await self._llm.achat(messages)\n",
    "\n",
    "        return Response(\n",
    "            response.message.content, source_nodes=[*text_results, *image_results]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multimodal_query_engine = SimpleMultiModalQueryEngine(\n",
    "    index=multi_modal_index,\n",
    "    image_top_k=3,\n",
    "    text_top_k=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try out the Query Engines and Compare!\n",
    "\n",
    "Now with our three query engines assembled, we can compare each approach with a rough \"vibes-based\" evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***********Baseline Query Engine***********\n",
      "The total fair value of marketable securities in 2020 was $190,516 million.\n",
      "\n",
      "***********Markdown Query Engine***********\n",
      "The total fair value of marketable securities in 2020 was $191,830 million.\n",
      "\n",
      "***********MultiModal Query Engine***********\n",
      "The total fair value of marketable securities in 2020 was $191,830 million.\n"
     ]
    }
   ],
   "source": [
    "query = \"What were the total fair value of marketable securities in 2020\"\n",
    "\n",
    "response_1 = await baseline_query_engine.aquery(query)\n",
    "print(\"\\n***********Baseline Query Engine***********\")\n",
    "print(response_1)\n",
    "\n",
    "response_2 = await markdown_query_engine.aquery(query)\n",
    "print(\"\\n***********Markdown Query Engine***********\")\n",
    "print(response_2)\n",
    "\n",
    "response_3 = await multimodal_query_engine.aquery(query)\n",
    "print(\"\\n***********MultiModal Query Engine***********\")\n",
    "print(response_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the multimodal and markdown query engines are able to retrieve the correct content, while the default query engine struggles to find the correct total value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also inspect the source nodes, and see the pages that were retrieved. Here is the correct page for the total fair value of marketable securities in 2020:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'images/page_41.jpg'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_3.source_nodes[4].node.image_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try a few more queries to see how the query engines perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***********Baseline Query Engine***********\n",
      "The effective interest rates for the debt issuances in 2021 were as follows:\n",
      "\n",
      "- Floating-rate notes: 0.48% – 0.63%\n",
      "- Fixed-rate notes: 0.03% – 4.78% for maturities from 2022 to 2060\n",
      "- Fixed-rate notes issued in the second quarter: 0.75% – 2.81% for maturities from 2026 to 2061\n",
      "- Fixed-rate notes issued in the fourth quarter: 1.43% – 2.86% for maturities from 2028 to 2061\n",
      "\n",
      "***********Markdown Query Engine***********\n",
      "The effective interest rates for the debt issuances in 2021 were as follows:\n",
      "\n",
      "- Floating-rate notes: 0.48% – 0.63%\n",
      "- Fixed-rate notes: 0.03% – 4.78% for the 0.000% – 4.650% notes, 0.75% – 2.81% for the 0.700% – 2.800% notes, and 1.43% – 2.86% for the 1.400% – 2.850% notes.\n",
      "\n",
      "***********MultiModal Query Engine***********\n",
      "The effective interest rates of all debt issuances in 2021 were as follows:\n",
      "\n",
      "1. **Floating-rate notes**: 0.48% – 0.63%\n",
      "2. **Fixed-rate 0.000% – 4.650% notes**: 0.03% – 4.78%\n",
      "3. **Fixed-rate 0.700% – 2.800% notes**: 0.75% – 2.81%\n",
      "4. **Fixed-rate 1.400% – 2.850% notes**: 1.43% – 2.86%\n"
     ]
    }
   ],
   "source": [
    "query = \"What were the effective interest rates of all debt issuances in 2021\"\n",
    "\n",
    "response_1 = await baseline_query_engine.aquery(query)\n",
    "print(\"\\n***********Baseline Query Engine***********\")\n",
    "print(response_1)\n",
    "\n",
    "response_2 = await markdown_query_engine.aquery(query)\n",
    "print(\"\\n***********Markdown Query Engine***********\")\n",
    "print(response_2)\n",
    "\n",
    "response_3 = await multimodal_query_engine.aquery(query)\n",
    "print(\"\\n***********MultiModal Query Engine***********\")\n",
    "print(response_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***********Baseline Query Engine***********\n",
      "The federal deferred tax amounts for the years 2019 to 2021 are as follows (in millions):\n",
      "\n",
      "- **2019**: $(2,939)\n",
      "- **2020**: $(3,619)\n",
      "- **2021**: $(7,176)\n",
      "\n",
      "These figures represent the deferred tax expense for each respective year.\n",
      "\n",
      "***********Markdown Query Engine***********\n",
      "As of September 25, 2021, the total deferred tax assets and liabilities for the years 2021 and 2020 are as follows:\n",
      "\n",
      "**Deferred Tax Assets:**\n",
      "- 2021: $25,176 million\n",
      "- 2020: $19,336 million\n",
      "\n",
      "**Deferred Tax Liabilities:**\n",
      "- 2021: $7,200 million\n",
      "- 2020: $10,138 million\n",
      "\n",
      "**Net Deferred Tax Assets:**\n",
      "- 2021: $13,073 million\n",
      "- 2020: $8,157 million\n",
      "\n",
      "The information for 2019 is not provided in the context.\n",
      "\n",
      "***********MultiModal Query Engine***********\n",
      "The federal deferred tax assets and liabilities for the years 2019 to 2021 are as follows:\n",
      "\n",
      "### Deferred Tax Assets (in millions):\n",
      "- **2021**: $25,176\n",
      "- **2020**: $19,336\n",
      "- **2019**: Not specified in the provided content.\n",
      "\n",
      "### Deferred Tax Liabilities (in millions):\n",
      "- **2021**: $7,200\n",
      "- **2020**: $10,138\n",
      "- **2019**: Not specified in the provided content.\n",
      "\n",
      "### Net Deferred Tax Assets (in millions):\n",
      "- **2021**: $13,073\n",
      "- **2020**: $8,157\n",
      "- **2019**: Not specified in the provided content.\n",
      "\n",
      "The significant components of deferred tax assets and liabilities reflect the effects of tax credits and temporary differences between financial statement carrying amounts and their respective tax bases.\n"
     ]
    }
   ],
   "source": [
    "query = \"federal deferred tax in 2019-2021\"\n",
    "\n",
    "response_1 = await baseline_query_engine.aquery(query)\n",
    "print(\"\\n***********Baseline Query Engine***********\")\n",
    "print(response_1)\n",
    "\n",
    "response_2 = await markdown_query_engine.aquery(query)\n",
    "print(\"\\n***********Markdown Query Engine***********\")\n",
    "print(response_2)\n",
    "\n",
    "response_3 = await multimodal_query_engine.aquery(query)\n",
    "print(\"\\n***********MultiModal Query Engine***********\")\n",
    "print(response_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***********Baseline Query Engine***********\n",
      "The current state taxes for the years 2019 to 2021 are as follows (in millions):\n",
      "\n",
      "- 2021: $1,620\n",
      "- 2020: $455\n",
      "- 2019: $475\n",
      "\n",
      "This indicates an increase of $1,165 million from 2020 to 2021, a decrease of $20 million from 2018 to 2019, and an increase of $80 million from 2019 to 2020.\n",
      "\n",
      "***********Markdown Query Engine***********\n",
      "The current state taxes for the years 2019 to 2021 are as follows (in millions):\n",
      "\n",
      "- **2021**: $1,620\n",
      "- **2020**: $455\n",
      "- **2019**: $475\n",
      "\n",
      "The changes in current state taxes from year to year are:\n",
      "\n",
      "- From 2019 to 2020: Decrease of $20 million\n",
      "- From 2020 to 2021: Increase of $1,165 million\n",
      "\n",
      "***********MultiModal Query Engine***********\n",
      "The current state taxes for the years 2019 to 2021 are as follows (in millions):\n",
      "\n",
      "- **2021**: $1,620\n",
      "- **2020**: $455\n",
      "- **2019**: $475\n",
      "\n",
      "So, the changes are:\n",
      "- From 2019 to 2020: Decrease of $20 million\n",
      "- From 2020 to 2021: Increase of $1,165 million\n"
     ]
    }
   ],
   "source": [
    "query = \"current state taxes per year in 2019-2021 (include +/-)\"\n",
    "\n",
    "response_1 = await baseline_query_engine.aquery(query)\n",
    "print(\"\\n***********Baseline Query Engine***********\")\n",
    "print(response_1)\n",
    "\n",
    "response_2 = await markdown_query_engine.aquery(query)\n",
    "print(\"\\n***********Markdown Query Engine***********\")\n",
    "print(response_2)\n",
    "\n",
    "response_3 = await multimodal_query_engine.aquery(query)\n",
    "print(\"\\n***********MultiModal Query Engine***********\")\n",
    "print(response_3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama-parse-aNC435Vv-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
